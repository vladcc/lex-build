#!/usr/bin/awk -f

# Author: Vladimir Dinev
# vld.dinev@gmail.com
# 2021-05-19

# Generates a lexer in C. The lexing strategy is quite simple - the next token
# is determined by switch-ing on the class of the current input character and
# then branching on the value of the next character. When a pattern is needed,
# like a number constant, or an id, this is offloaded to the user by the means
# of callback functions. There are two ways to distinguish between keywords and
# ids - an optimized bsearch(), or a literal if - else if tree. The interface
# to both is the same - after an id has been read you call the function and the
# return value is either the token for the keyword in the lexer write buffer, or
# a user provided default value.

# <script>
function SCRIPT_NAME() {return "lex-c.awk"}
function SCRIPT_VERSION() {return "1.0"}
# </script>

# <out_signature>
function out_signature() {
	out_line(sprintf("// generated by %s %s", SCRIPT_NAME(), SCRIPT_VERSION()))
}
# </out_signature>

# <out_header>
function out_header() {
	out_line("// <lex_header>")
	out_signature()
	out_line("#ifndef LEX_H")
	out_line("#define LEX_H")
	out_line()
	out_line("#include <stdbool.h>")
	out_line()
	out_tok_enum()
	out_line()
	out_lex_define()
	out_line()
	out_line("#endif")
	out_line("// </lex_header>")
}
function out_lex_cls_events_memb(    _set, _i, _end, _str) {
	arr_make_set(_set, G_actions_arr, 2)

	_end = arr_len(_set)
	for(_i = 1; _i <= _end; ++_i) {
		_str = _set[_i]
		if (match(_str, "\\(\\)$")) {
			gsub("\\(\\)", "", _str)
			out_line(sprintf("cls_action %s;", _str))
		}
	}
	out_line("cls_action on_unknown_ch;")
}
function out_lex_prereq(    _set, _i, _end, _str) {
	out_line("typedef unsigned int uint;")
	out_line("typedef const char * (*buff_in)(void * arg);")
	out_line("typedef struct lex_io {")
	tab_inc()
	out_line("buff_in get_data; // return more input; "\
		"return \"\" when done, never NULL")
	out_line("void * usr_arg;   // the argument to get_data")
	out_line("char * write_buff;   // lex_save_ch() saves here")
	out_line("uint write_buff_len; // includes the '\\0'")
	tab_dec()
	out_line("} lex_io;")
	out_line()
	out_line("typedef struct lex_state lex_state;")
	out_line("typedef tok_id (*cls_action)(lex_state * lex);") 
	out_line("typedef struct lex_events {")
	tab_inc()
	out_lex_cls_events_memb()
	tab_dec()
	out_line("} lex_events;")
}
function out_lex_define(    _set, _i, _end, _str) {
	out_lex_prereq()
	out_line();
	out_line("typedef struct lex_state {")
	tab_inc()
	out_line("const char * input;")
	out_line("uint input_pos;")
	out_line("uint input_line;")
	out_line("int curr_ch;")
	out_line("tok_id curr_tok;")
	out_line("buff_in get_data;")
	out_line("void * usr_arg;")
	out_line("char * write_buff;")
	out_line("uint write_buff_len;")
	out_line("uint write_buff_pos;")
	out_lex_cls_events_memb()
	tab_dec()
	out_line("} lex_state;")
	out_line()

	out_line("// read the next character, advance the input")
	out_line("static inline int lex_read_ch(lex_state * lex)")
	out_line("{")
	tab_inc()
	out_line("lex->curr_ch = *lex->input++;")
	out_line("++lex->input_pos;")
	out_line("if (!(*lex->input))")
	tab_inc()
	out_line("lex->input = lex->get_data(lex->usr_arg);")
	tab_dec()
	out_line("return lex->curr_ch;")
	tab_dec()
	out_line("}")

	out_line()
	out_line("// look at, but do not read, the next character")
	out_line("static inline int lex_peek_ch(lex_state * lex)")
	out_line("{return *lex->input;}")
	out_line()
	out_line("// call this before writing to the lexer write space")
	out_line("static inline void lex_save_begin(lex_state * lex)")
	out_line("{lex->write_buff_pos = 0;}")
	out_line()

	out_line("// call this to write to the lexer write space")
	out_line("static inline bool lex_save_ch(lex_state * lex)")
	out_line("{")
	tab_inc()
	out_line("bool is_saved = (lex->write_buff_pos < lex->write_buff_len);") 
	out_line("if (is_saved)")
	tab_inc()
	out_line("lex->write_buff[lex->write_buff_pos++] = lex->curr_ch;")
	tab_dec()
	out_line("return is_saved;")
	tab_dec()
	out_line("}")
	
	out_line()
	out_line("// call this after you're done writing to the lexer write space")
	out_line("static inline void lex_save_end(lex_state * lex)")
	out_line("{lex->write_buff[lex->write_buff_pos] = '\\0';}")
	out_line()
	out_line("// get what you've written")
	out_line("static inline char * lex_get_saved(lex_state * lex)")
	out_line("{return lex->write_buff;}")
	out_line()
	out_line("// see how long it is")
	out_line("static inline uint lex_get_saved_len(lex_state * lex)")
	out_line("{return lex->write_buff_pos;}")
	out_line()
	out_line("// so it's possible for the user to access their argument back")
	out_line("static inline void * lex_get_usr_arg(lex_state * lex)")
	out_line("{return lex->usr_arg;}")
	out_line()
	out_line("// get the character position on the current input line")
	out_line("static inline uint lex_get_input_pos(lex_state * lex)")
	out_line("{return lex->input_pos;}")
	out_line()
	out_line("// get the number of the current input line")
	out_line("static inline uint lex_get_input_line_no(lex_state * lex)")
	out_line("{return lex->input_line;}")
	out_line()
	out_line("// get the last character the lexer read")
	out_line("static inline int lex_get_curr_ch(lex_state * lex)")
	out_line("{return lex->curr_ch;}")
	out_line()
	out_line("// get the last token the lexer read")
	out_line("static inline tok_id lex_get_curr_tok(lex_state * lex)")
	out_line("{return lex->curr_tok;}")
	out_line()
	out_line("// see if tok is the same as the token in the lexer")
	out_line("static inline bool lex_match(lex_state * lex, tok_id tok)")
	out_line("{return (lex->curr_tok == tok);}")
	out_line()
	
	out_line(sprintf("%s lex_init(%s)",
		"static inline void",
		"lex_state * lex, lex_io * io, lex_events * events"))
	out_line("{")
	tab_inc()
	out_line("lex->get_data = io->get_data;")
	out_line("lex->usr_arg = io->usr_arg;")
	out_line("lex->input = lex->get_data(lex->usr_arg);")
	out_line("lex->input_pos = 0;")
	out_line("lex->input_line = 1;")
	out_line("lex->curr_ch = -1;")
	out_line(sprintf("lex->curr_tok = %s;", TOK_ERR_ENUM()))
	out_line("lex->write_buff = io->write_buff;")
	out_line("lex->write_buff_len = io->write_buff_len;")
	out_line("lex->write_buff_pos = 0;")
	
	arr_make_set(_set, G_actions_arr, 2)
	_end = arr_len(_set)
	for(_i = 1; _i <= _end; ++_i) {
		_str = _set[_i]
		if (match(_str, "\\(\\)$")) {
			gsub("\\(\\)", "", _str)
			out_line(sprintf("lex->%s = events->%s;", _str, _str))
		}
	}
	out_line("lex->on_unknown_ch = events->on_unknown_ch;")
	tab_dec()
	out_line("}")

	out_line()
	out_line("// returns the string representation of tok")
	out_line("const char * lex_tok_to_str(tok_id tok);")
	out_line()
	out_line("// reads and returns the next token from the input")
	out_line("tok_id lex_next(lex_state * lex);")
	out_line()
	if (has_keywords()) {
		out_line("// returns the token for the keyword in lex's write buffer, "\
			"or base if not a")
		out_line(sprintf("// keyword; lookup method: %s", get_kw_type()))
		out_line(sprintf("%s;", IS_KW_HEAD()))
	}
}
function out_tok_enum(    _set, _set_const, _set_str, _i, _end, _line_len, _j) {
	arr_make_set(_set, G_symbols_arr, 2)
	arr_copy(_set_const, _set)
	arr_make_set(_set, G_keywords_arr, 2)
	arr_append(_set_const, _set)
	arr_make_set(_set, G_patterns_arr, 2)
	arr_append(_set_const, _set)

	arr_make_set(_set, G_symbols_arr, 1)
	arr_copy(_set_str, _set)
	arr_make_set(_set, G_keywords_arr, 1)
	arr_append(_set_str, _set)
	arr_make_set(_set, G_patterns_arr, 1)
	arr_append(_set_str, _set)
	
	out_line("typedef enum tok_id {")

	# Print _line_len enum values per line.
	_line_len = 4
	_i = 1
	_end = arr_len(_set_const)
	
	while (_i <= _end) {

		# Print the token value enum constant name.
		for (_j = 0; _j < _line_len && _i+_j <= _end; ++_j) 
			printf("%-20s", sprintf("%s,", _set_const[_i+_j]))
		out_line()

		# Print the token string as a comment below.
		for (_j = 0; _j < _line_len && _i+_j <= _end; ++_j)
			printf("%-20s", sprintf("/* \"%s\" */", _set_str[_i+_j]))
		out_line()

		_i += _j
		
	}
	
	out_line(sprintf("%s," , TOK_ERR_ENUM()))
	out_line(sprintf("/* \"%s\" */", TOK_ERR_STR()))

	out_line("} tok_id;")
}
# </out_header>

# <out_source>
function out_source() {
	out_line("// <lex_source>")
	out_signature()
	out_line("#include \"lex.h\"")

	if (get_kw_type() != KW_IFS()) {
		out_line("#include <string.h>")
		out_line("#include <stdlib.h>")
	}
	
	out_line()
	out_tok_tbl()
	out_line()
	out_tok_to_str()
	out_line()
	out_all_char_tbl()
	out_line()
	out_keywords()
	out_line("// </lex_source>")
}
# <tok_tbl>
function TOK_ERR_STR() {return "I am Error"}
function TOK_ERR_ENUM() {return "TOK_ERROR"}
function out_tok_tbl(    _set, _set_str, _set_const, _i, _end, _line_len, _j) {
	arr_make_set(_set, G_symbols_arr, 1)
	arr_copy(_set_str, _set)
	arr_make_set(_set, G_keywords_arr, 1)
	arr_append(_set_str, _set)
	arr_make_set(_set, G_patterns_arr, 1)
	arr_append(_set_str, _set)

	arr_make_set(_set, G_symbols_arr, 2)
	arr_copy(_set_const, _set)
	arr_make_set(_set, G_keywords_arr, 2)
	arr_append(_set_const, _set)
	arr_make_set(_set, G_patterns_arr, 2)
	arr_append(_set_const, _set)

	
	# Print all tokens in a static string table.
	out_line("static const char * tokens[] = {")

	# Print _line_len tokens per line.
	_line_len = 4
	_i = 1
	_end = arr_len(_set_str)
	while (_i <= _end) {

		# Print the token string representation.
		for (_j = 0; _j < _line_len && _i+_j <= _end; ++_j) 
			printf("%-20s", sprintf("\"%s\",", _set_str[_i+_j]))
		out_line()

		# Print the name of its enum constant as a comment below.
		for (_j = 0; _j < _line_len && _i+_j <= _end; ++_j)
			printf("%-20s", sprintf("/* %s */", _set_const[_i+_j]))		
		out_line()
		
		_i += _j
	}
	
	out_line(sprintf("\"%s\"," , TOK_ERR_STR()))
	out_line(sprintf("/* %s */", TOK_ERR_ENUM()))
	
	out_line("};")

}
# </tok_tbl>
# <lex_tok_to_str>
function out_tok_to_str() {
	out_line("const char * lex_tok_to_str(tok_id tok)")
	out_line("{")
	tab_inc()
	out_line("return tokens[tok];")
	tab_dec()
	out_line("}")
}
# </lex_tok_to_str>
# <char_tbls>
function out_all_char_tbl() {
	out_ch_cls_enum()
	out_line()
	out_char_tbl()
	out_line()
	out_lex_next()
}
function out_ch_cls_enum(    _i, _end, _cls_set, _line_len) {
	arr_make_set(_cls_set, G_char_tbl_arr, 2)

	out_line("enum char_cls {")
	
	_line_len = 4
	_i = 1
	_end = arr_len(_cls_set)
	
	while (_i <= _end) {
	
		for (_j = 0; _j < _line_len && _i+_j <= _end; ++_j) {
			if ((_i+_j) == 1)
				printf("%-20s", sprintf("%s = 1,", _cls_set[_i+_j]))
			else
				printf("%-20s", sprintf("%s,", _cls_set[_i+_j]))
		}
		out_line()
		
		_i += _j
	}
	
	out_line("};")
}
function out_char_tbl(    _i, _end, _ch, _str, _map_ch_cls,
_zero_line_len, _zero_new_line, _j, _ch_out) {
	out_line("#define CHAR_TBL_SZ (0xFF+1)")
	out_line("typedef unsigned char byte;")

	# Print a static constant table for the character classes.
	# Prints at most 16 zeroes, or two char classes along with their values as
	# comments per line.
	out_line("static const byte char_cls_tbl[CHAR_TBL_SZ] = {")

	map_from_arr(_map_ch_cls, G_char_tbl_arr)

	_zero_new_line = 0
	_zero_line_len = 16

	_i = 0
	_end = CHR_TBL_END()
	while (_i < _end) {
		_j = 0
		do {
			_ch = n_to_ch(_i)

			if (" " == _ch)
				_ch = CH_ESC_SPACE()

			_zero_new_line = 0
			if (!(_ch in _map_ch_cls)) {

				if (_ch_out) {
					out_line()
					_ch_out = 0
				}
				
				if (!(_j % _zero_line_len))
					out_tabs()

				printf("0, ")

				if ((_j % _zero_line_len) == (_zero_line_len - 1)) {
					out_line()
					_zero_new_line = 1
				}
				
				++_j
				++_i
			}
		} while (!(_ch in _map_ch_cls) && _i < _end)

		if (_j && !_zero_new_line)
			out_line()
		
		if (!(_i < _end))
			break

		if ("\\" == _ch)
			_str = "\\\\"
		else if (CH_ESC_SPACE() == _ch)
			_str = " "
		else
			_str = _ch
	
		printf("%-35s ",
			sprintf("/* %03d 0x%02X '%s' */ %s,",
				_i, _i, _str, _map_ch_cls[_ch]))
		
		++_ch_out
		if (2 == _ch_out) {
			out_line()
			_ch_out = 0
		}
		
		++_i
	}
		
	out_line("};")
	
	out_line("#define char_cls_get(ch) ((byte)char_cls_tbl[(byte)(ch)])")
}

function out_kw_const() {
	out_line(sprintf("#define KW_LONG  %d // longest keyword length",
		kw_longest()))
	out_valid_len()
}
# </char_tbls>
function CHR_TBL_END() {return 128}
# <lex_next>
function out_tree_symb(tree, root, map_tok,    _next_str, _next_ch, _i, _end) {
	# E.g. "=", "==", "=!" becomes
	# if ('=' == next_ch()) {
	#     tok = "="
	#     read_ch()
	#     if ('=' == next_ch()) {
	#         tok = "=="
	#         read_ch()
	#      } else if ('!' == next_ch()) {
	#         tok = "=!"
	#         read_ch()
	#      }
	# }
	
	if (ch_ptree_has(tree, root) || ch_ptree_is_word(tree, root)) {

		if (ch_ptree_is_word(tree, root))
			out_line(sprintf("tok = %s;", map_tok[root]))
			
		_next_str = ch_ptree_get(tree, root)
		_end = length(_next_str)
		for (_i = 1; _i <= _end; ++_i) {
			_next_ch = str_ch_at(_next_str, _i)

			if (_end > 1) {
				# If more than one call to lex_peek_ch() is needed, cache the
				# result into peek_ch.
				
				if (1 == _i)
					out_line("peek_ch = lex_peek_ch(lex);")
			
				out_line(sprintf("%s ('%s' == peek_ch)",
					(_i == 1) ? "if" : "else if" ,_next_ch))
			} else {
				# Do not cache for only a single call.
				
				out_line(sprintf("%s ('%s' == lex_peek_ch(lex))",
					(_i == 1) ? "if" : "else if" ,_next_ch))
			}
			
			out_line("{")
			tab_inc()
			out_line("lex_read_ch(lex);")
			out_tree_symb(tree, (root _next_ch), map_tok)

			tab_dec()
			out_line("}")
		}
	}
}
function out_lex_next(    _i, _end, _cls_set, _cls, _act, _map_cls_chr,
_map_symb, _map_act, _tree, _tmp, _dont_go) {

	# Generates lex_next(), which is a big switch statement which switches on
	# the class of the current character. The class values are contiguous, so
	# it's easy for a compiler to turn the switch into a jump table. The class
	# of the character is derived by a quick table lookup, e.g. ch_cls[curr_ch]
	# In each case, either a token is found, a user callback is called, or some
	# custom to the lexer action is performed. E.g.:
	# ...
	# case CH_GT: /* '>' */
	#     tok = TOK_GT;
	#     if (next_ch() == '=')
	#         tok = TOK_GEQ;
	# ...
	# case CH_WORD: // a-z A-Z _
	#     tok = usr_defined_get_kword()
	# ...
	# case CH_NEW_LINE:
	#     ++lex->line_no;
	# ...
	
	arr_make_set(_cls_set, G_char_tbl_arr, 2)
	
	out_line("tok_id lex_next(lex_state * lex)")
	out_line("{")
	tab_inc()

	out_line("int peek_ch = 0;")
	out_line(sprintf("tok_id tok = %s;", TOK_ERR_ENUM()))
	out_line("while (true)")
	out_line("{")
	tab_inc()
	
	out_line("switch (char_cls_get(lex_read_ch(lex)))")
	out_line("{")
	tab_inc()

	map_from_arr(_map_cls_chr, G_char_tbl_arr, 2, 1)
	map_from_arr(_map_symb, G_symbols_arr)
	map_from_arr(_map_act, G_actions_arr)
	ch_ptree_init(_tree)

	for (_tmp in _map_symb) {
		# Constants are not symbol tokens. I.e. EOI (end of input) can exist in
		# the symbol table, but the character sequence E O I is not a token in
		# the sense in which "==" is for example, so don't put it in the tree
		# with the other tokens.
		
		if (!is_constant(_tmp))
			ch_ptree_insert(_tree, _tmp)
	}

	_end = arr_len(_cls_set)
	for (_i = 1; _i <= _end; ++_i) {
		_cls = _cls_set[_i]
		_dont_go = 0 # <-- stays 0 if a complete token was read

		if (match(_cls, CH_CLS_AUTO_RE()))
			out_line(sprintf("case %s: /* '%s' */", _cls, _map_cls_chr[_cls]))
		else
			out_line(sprintf("case %s:", _cls))
		
		out_line("{")
		tab_inc()
		
		if (_cls in _map_act) {
			_act = _map_act[_cls]
			if (match(_act, "\\(\\)$")) {
				# If the action ends in (), then it's a user defined callback,
				# which has to take lex as an argument.
				
				sub("\\(\\)", "(lex)", _act)
				out_line(sprintf("tok = lex->%s;", _act))
			} else if (NEXT_CH() == _act) {
				# Immediately jump back to the top of the loop on white space.
				
				_dont_go = 1
				out_line("continue;")
			} else if (NEXT_LINE() == _act) {
				# Count lines.
				
				out_line("++lex->input_line;")
				out_line("lex->input_pos = 0;")
				out_line("continue;")
				_dont_go = 1
			} else if (is_constant(_act)) {
				# Constants are assumed to be meaningful token enums.
				
				out_line(sprintf("tok = %s;", _act))
			} else {
				# Should never happen.
				
				out_line("#error \"unknown action\"")
			}
		} else {
			# Generate if trees for all tokens which begin with the current
			# character class and are longer than a single character. The
			# character class is assumed to represent only a single character.
			
			_tmp = _map_cls_chr[_cls]
			if (length(_tmp) == 1)
				out_tree_symb(_tree, _tmp, _map_symb)
		}

		if (!_dont_go)
			out_line("goto done;")
			
		tab_dec()
		out_line("} break;")
	}
	out_line("default:")
	out_line("{")
	tab_inc()
	
	# Called on weird input, e.g. an '@' character in a C file.
	out_line("tok = lex->on_unknown_ch(lex);")
	out_line("goto done;")
	tab_dec()
	out_line("} break;")
		
	tab_dec()
	out_line("}")
	tab_dec()
	out_line("}")

	print "done:"
	out_line("return (lex->curr_tok = tok);")
	tab_dec()
	out_line("}")
}
# </lex_next>
# <keywords>
function kw_longest(    _set, _i, _end, _max, _n) {
	arr_make_set(_set, G_keywords_arr)

	_max = length(_set[1])
	_end = arr_len(_set)
	for (_i = 2; _i <= _end; ++_i) {
		_n = length(_set[_i])
		if (_n > _max)
			_max = _n
	}
	
	return _max
}

function has_keywords() {return arr_len(G_keywords_arr)}
function set_kw_type(str) {_B_kw_type = str}
function get_kw_type() {return _B_kw_type}

function out_keywords() {
	if (has_keywords()) {
		out_line("// <lex_keyword_or_base>")

		out_kw_const()
		
		out_line()
		
		if (get_kw_type() == KW_BSEARCH())
			out_kw_bsrch()
		else if (get_kw_type() == KW_IFS())
			out_kw_ifs()

		out_line("// </lex_keyword_or_base>")
	}
}
function IS_KW_HEAD() {
	return "tok_id lex_keyword_or_base(lex_state * lex, tok_id base)"
}
function out_is_kw_head() {out_line(IS_KW_HEAD())}
function KW_LEN_LIMIT() {return 31}
function out_valid_len(    _i, _end, _j, _jend, _valid_lengths, _arr, _kw_len,
_bin_str, _add) {
	# Generate a bitmap of valid keyword lengths. Bit number 0 is always 0. If
	# there are keywords with a length of 1, then bit number 1 is 1, if not,
	# then it's 0. If there are keywords 2 characters long, then bit 2 is 1, 0
	# if there aren't, etc. You can then easily check if a keyword of length
	# n exists by (VALID_LENGTHS & (1 << n)), given n <= 31.
	
	_end = KW_LEN_LIMIT()
	_jend = arr_len(G_keywords_sort_len_arr)

	# Get the actual int value of the bit map.
	_valid_lengths = 0
	for (_i = 1; _i <= _end; ++_i) {
		for (_j = 1; _j <= _jend; ++_j) {
			unjoin(_arr, G_keywords_sort_len_arr[_j])
			_kw_len = _arr[2]
			if (_i == _kw_len) {
				_valid_lengths = or(_valid_lengths, lshift(1, _i))
				break
			}
		}
	}

	# Get the binary representation of the int bitmap value as a string.
	_bin_str = "0"
	for (_i = 1; _i <= _end; ++_i) {
		_add = "0"
		for (_j = 1; _j <= _jend; ++_j) {
			unjoin(_arr, G_keywords_sort_len_arr[_j])
			_kw_len = _arr[2]
			if (_i == _kw_len)
				_add = "1"
		}
		if (!(_i % 8))
			_bin_str = (" " _bin_str)
		else if (!(_i % 4))
			_bin_str = ("_" _bin_str)
			
		_bin_str = (_add _bin_str)
	}

	out_line(sprintf("#define VALID_LENGTHS 0x%08XU // %s",
		_valid_lengths, _bin_str))
	out_line("#define is_valid_len(len) (VALID_LENGTHS & (1 << (len)))")
}

function KW_LEN_CHECK() {
	return "(txt_len <= KW_LONG && is_valid_len(txt_len))"
}

# <lex_kw_lookup_bsearch>
function out_kw_struct_arr(    _map_kw, _arr, _i, _end, _kw, _kw_len,
_j, _jend, _len_start, _len_len) {
	map_from_arr(_map_kw, G_keywords_arr)

	_end = arr_len(G_keywords_sort_len_arr)

	# An array of elements {"keyword", TOK_KEYWORD} where keywords of the same
	# length appear next to each other in alphabetical order. This allows for
	# bsearch only on the range of keywords with the same length as the input.

	out_line("// ordered by length and value; don't jumble up")
	out_line(sprintf("static const str_tok kws[%d] = {", _end))
	
	for (_i = 1; _i <= _end; ++_i) {
		unjoin(_arr, G_keywords_sort_len_arr[_i])
		_kw = _arr[1]
		_kw_len = _arr[2]
		out_line(sprintf("%s %s %s",
			sprintf("/* %02d */", _i-1),
			sprintf("{\"%s\", %s},", _kw, _map_kw[_kw]),
			sprintf("// %d", _kw_len)))
	}
	out_line("};")
	
	out_line()
	out_line("typedef struct kw_len_data {")
	tab_inc()
	out_line("byte start;")
	out_line("byte len;")
	tab_dec()
	out_line("} kw_len_data;")

	out_line()

	_end = kw_longest()

	# The table which tells you where the range of keywords with a particular
	# length begins and how long it is.
	out_line("static const kw_len_data kws_len[KW_LONG+1] = {")
	tab_inc()
	out_line("{0, 0}, // always empty; can't have keywords of length 0")
	
	_jend = arr_len(G_keywords_sort_len_arr)
	for (_i = 1; _i <= _end; ++_i) {
		_len_start = 0
		_len_len = 0
		for (_j = 1; _j <= _jend; ++_j) {
			unjoin(_arr, G_keywords_sort_len_arr[_j])
			_kw_len = _arr[2]
			if (_i == _kw_len) {
				if (!_len_start) 
					_len_start = _j
				++_len_len
			}
		}

		if (_len_start)
			--_len_start
			
		out_line(sprintf("{%d, %d}, // %d", _len_start, _len_len, _i))
	}
	
	tab_dec()
	out_line("};")
}
function out_bsrch_prereq() {
	out_line("typedef struct str_tok {")
	tab_inc()
	out_line("const char * str;")
	out_line("tok_id tok;")
	tab_dec()
	out_line("} str_tok;")
	out_line("static int compar(const void * a, const void * b)")
	out_line("{")
	tab_inc()
	out_line("const char * key = (const char *)a;")
	out_line("const str_tok * stb = (const str_tok *)b;")
	out_line("return strcmp(key, stb->str);")
	tab_dec()
	out_line("}")
}
function out_kw_bsrch() {
	out_bsrch_prereq()
	out_line()
	out_is_kw_head()
	out_line("{")
	tab_inc()

	out_kw_struct_arr()
	out_line()
	
	out_line("tok_id tok = base;")
	out_line("const char * txt = lex->write_buff;")
	out_line("uint txt_len = lex->write_buff_pos;")

	# Call bsearch() only if a keyword with length(input) exists and limit the
	# search to the range of keywords with exactly that length.
	
	out_line(sprintf("if %s", KW_LEN_CHECK()))
	out_line("{")
	tab_inc()
	out_line("str_tok * kw = (str_tok *)bsearch(txt,")
	tab_inc()
	out_line("kws+kws_len[txt_len].start,")
	out_line("kws_len[txt_len].len,")
	out_line("sizeof(*kws),")
	out_line("compar")
	tab_dec()
	out_line(");")
	out_line("return ((!kw) ? tok : kw->tok);")
	tab_dec()
	out_line("}")
	out_line("return tok;")
	tab_dec()
	out_line("}")
}
# </lex_kw_lookup_bsearch>

# # <lex_kw_lookup_ifs>
function out_kw_walk(tree, root, map_kw, n,    _next, _ch, _i, _end) {

	if (ch_ptree_has(tree, root) || ch_ptree_is_word(tree, root)) {
	
		_ch = str_ch_at(root, length(root))
		out_line(sprintf("%s ('%s' == *ch)", (1 == n) ? "if" : "else if", _ch))
		out_line("{")
		tab_inc()
		out_line("++ch;")

		if (ch_ptree_is_word(tree, root))
			out_line(sprintf("tok = %s;", map_kw[root]))
		
		_next = ch_ptree_get(tree, root)
		_end = length(_next)
		for (_i = 1; _i <= _end; ++_i)
			out_kw_walk(tree, (root str_ch_at(_next, _i)), map_kw, _i)
			
		tab_dec()
		out_line("}")
	}
}
function out_kw_ifs(    _tree, _set_kw, _map_kw, _i, _end, _arr, _set_ch) {

	# Find out if, and which, keyword the input is by literal if statements for
	# each character.

	arr_make_set(_set_kw, G_keywords_arr, 1)
	map_from_arr(_map_kw, G_keywords_arr)
	ch_ptree_init(_tree)
	
	_end = arr_len(_set_kw)
	for (_i = 1; _i <= _end; ++_i) {
		ch_ptree_insert(_tree, _set_kw[_i])
		arr_push(_arr, str_ch_at(_set_kw[_i], 1))
	}
	arr_make_set(_set_ch, _arr)

	out_is_kw_head()
	out_line("{")
	tab_inc()
	out_line("tok_id tok = base;")
	out_line("uint txt_len = lex->write_buff_pos;")
	out_line()

	# Do not proceed if there are no keywords with length(input)
	out_line(sprintf("if (!%s)", KW_LEN_CHECK()))
	tab_inc()
	out_line("return tok;")
	tab_dec()
	
	out_line()
	out_line("const char * ch = lex->write_buff;")
	
	_end = arr_len(_set_ch)
	# Generate one big if - else if tree for all keywords.
	for (_i = 1; _i <= _end; ++_i)
		out_kw_walk(_tree, _set_ch[_i], _map_kw, _i)
	out_line()

	# Whatever the value of 'tok' is at this point, it is valid if and only if
	# '*ch' is at the end of the input. This ensures the longest possible match.
	# E.g. if the input is "dont" and "do" is a keyword, at this point 'tok'
	# would have the value of TOK_DO, given another keyword of length 4 exists.
	# This is not correct, as "do" is a prefix of "dont", so to be sure 'tok' is
	# actually the "do" keyword, '*ch' has to be at the end of the string.
	
	out_line("return ('\\0' == *ch) ? tok : base;")
	tab_dec()
	out_line("}")
}
# </lex_kw_lookup_ifs>
# </keywords>
# </out_source>

# <misc>
function get_kw_lens(    _i, _end, _str, _arr, _j, _jend, _arr2, _arr3, _n) {

	# Sorts all keywords by length and by value. I.e. all keywords of the same
	# length appear next to each other in alphabetical order.

	arr_init(_arr)

	_end = arr_len(G_keywords_arr)
	for (_i = 1; _i <= _end; ++_i) {
		unjoin(_arr2, G_keywords_arr[_i])
		_str = _arr2[1]
		arr_push(_arr, join(_str, length(_str)))
	}
	
	_end = kw_longest()
	_jend = arr_len(_arr)
	for (_i = 1; _i <= _end; ++_i) {
		delete _arr3
		_n = 0
		for (_j = 1; _j <= _jend; ++_j) {
			unjoin(_arr2, _arr[_j])
			if (_i == _arr2[2])
				_arr3[++_n] = _arr2[1]
		}
		
		if (_n) {
			asort(_arr3)
			for (_j = 1; _j <= _n; ++_j)
				arr_push(G_keywords_sort_len_arr, join(_arr3[_j], _i))
		}
	}

	_end = arr_len(G_keywords_sort_len_arr)
	unjoin(_arr2, G_keywords_sort_len_arr[_end])
	if (_arr2[2] > KW_LEN_LIMIT()) {
	
		# We have a limit because an int bitmap is used to check if a keyword
		# of a certain length exists.
	
		err_quit(sprintf("keyword length cannot be larger than %d",
			KW_LEN_LIMIT()))
	}
}
function generate() {
	get_kw_lens()
	out_header()
	out_source()
}
function KW_BSEARCH() {return "bsearch"}
function KW_IFS() {return "ifs"}
function check_kw(str) {
	if (str != KW_BSEARCH() && str != KW_IFS()) {
		err_quit(sprintf("Keywords has to be one of: %s, %s",
			KW_BSEARCH(), KW_IFS()))
	}
}
function err_quit(msg) {
	error_quit(msg, SCRIPT_NAME())
}

function on_help() {
print sprintf("%s -- lex-build C back end", SCRIPT_NAME())
print ""
print "Macros are replaced with static inline header functions, hence compiling"
print "with optimizations makes a huge difference."
print ""
print "Options:"
print sprintf("-vKeywords=%s/%s - specifies the keyword lookup method.",
	KW_BSEARCH(), KW_IFS())
print sprintf("%s - optimized binary search; generally <= work compared to " \
"hashing.", KW_BSEARCH())
print sprintf("%s     - a literal character by character if - else if tree. " \
"Generally linear.", KW_IFS())
print sprintf("Faster than %s, doesn't use stdlib.h and string.h, but more " \
"code. %s", KW_BSEARCH(), KW_BSEARCH())
print "is the default."
print ""
}

function on_version() {
print sprintf("%s %s", SCRIPT_NAME(), SCRIPT_VERSION())
}

function on_begin() {
	arr_init(G_char_tbl_arr)
	arr_init(G_symbols_arr)
	arr_init(G_keywords_arr)
	arr_init(G_patterns_arr)
	arr_init(G_actions_arr)
	arr_init(G_keywords_sort_len_arr)
	
	if (!Keywords)
		Keywords = KW_BSEARCH()
	
	check_kw(Keywords)
	set_kw_type(Keywords)
}
function on_char_tbl() {save_to(G_char_tbl_arr)}
function on_symbols()  {save_to(G_symbols_arr)}
function on_keywords() {save_to(G_keywords_arr)}
function on_patterns() {save_to(G_patterns_arr)}
function on_actions()  {save_to(G_actions_arr)}
function on_end()      {generate()}
# </misc>
