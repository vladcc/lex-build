#!/usr/bin/awk -f

# Author: Vladimir Dinev
# vld.dinev@gmail.com
# 2021-05-19

# Generates a lexer in awk. It determines the next token by branching on the
# character class of the current input character, and then branches on the next
# character value. Patterns, like constants and ids, are handled by user
# callbacks. An interface to distinguish between ids and keywords is provided.

# <script>
function SCRIPT_NAME() {return "lex-awk.awk"}
function SCRIPT_VERSION() {return "1.0"}
# </script>

# <out_signature>
function out_signature() {
	out_line(sprintf("# generated by %s %s", SCRIPT_NAME(), SCRIPT_VERSION()))
}
# </out_signature>

# <out_ch_tbl>
function TOK_ERR() {return "I am Error"}

function out_const(    _set, _set_const, _set_str, _i, _end, _ch_cls) {
	# Outputs awk 'constants'. E.g. In C you'd have
	# ...
	# enum { TOK_FOO = 0};
	# static const char * toks[] = {"foo"};
	# const char * tok_to_str(int tok) {return toks[tok];}
	# ...
	# In awk this would be
	# ...
	# function TOK_FOO() {return "foo"}
	# ...
	# So, functions instead of enums and tables. Since strings are scalar types
	# in awk, the return value of the function is the actual string
	# representation of the token. Character classes are handled similarly. E.g.
	# ...
	# enum {CH_CLS_FOO = 1, CH_CLS_BAR};
	# ...
	# becomes
	# ...
	# function CH_CLS_FOO() {return 1}
	# function CH_CLS_BAR() {return 2}
	# ...
 
	arr_make_set(_set, G_symbols_arr, 2)
	arr_copy(_set_const, _set)
	arr_make_set(_set, G_keywords_arr, 2)
	arr_append(_set_const, _set)
	arr_make_set(_set, G_patterns_arr, 2)
	arr_append(_set_const, _set)

	arr_make_set(_set, G_symbols_arr, 1)
	arr_copy(_set_str, _set)
	arr_make_set(_set, G_keywords_arr, 1)
	arr_append(_set_str, _set)
	arr_make_set(_set, G_patterns_arr, 1)
	arr_append(_set_str, _set)

	out_line()
	out_line("# the only way to have immutable values; use as constants")

	# Tokens.
	_end = arr_len(_set_const)
	for (_i = 1; _i <= _end; ++_i) {
		out_line(sprintf("function %s() {return \"%s\"}",
			_set_const[_i], _set_str[_i]))
	}
	out_line(sprintf("function TOK_ERROR() {return \"%s\"}", TOK_ERR()))
	out_line()
	
	arr_make_set(_set, G_char_tbl_arr, 2)

	# Char classes.
	_end = arr_len(_set)
	for (_i = 1; _i <= _end; ++_i) {
		_ch_cls = _set[_i]
		out_line(sprintf("function %s() {return %d}", _ch_cls, _i))
		ch_cls_to_const_map_add(_ch_cls, _i)
	}
}

function out_init_ch_tbl(    _i, _end, _ch, _cls, _split) {
	# Generates the mapping between characters and their classes. E.g.
	# n["a"] = CH_CLS_WORD()
	# n["b"] = CH_CLS_WORD()
	# ...
	# n["0"] = CH_CLS_NUM()
	# n["1"] = CH_CLS_NUM()
	# ...

	out_line("function _lex_init_ch_tbl() {")
	tab_inc()

	_end = arr_len(G_char_tbl_arr)
	for (_i = 1; _i <= _end; ++_i) {
		unjoin(_split, G_char_tbl_arr[_i])
		_ch = _split[1]
		_cls = _split[2]

		if (CH_ESC_SPACE() == _ch)
			_ch = " "
		else if ("\\0" == _ch)
			_ch = ""
		
		out_line(sprintf("_B_lex_ch_tbl[\"%s\"] = %s()", _ch, _cls))
	}
	
	tab_dec()
	out_line("}")
}
# </out_ch_tbl>

# <out_kwds>
function out_kwds(    _set, _i, _end) {
	# Generates the keyword map. E.g.
	# ...
	# n["if"] = 1
	# n["else"] = 1
	# ...
	
	out_line("function _lex_init_keywords() {")
	tab_inc()

	arr_make_set(_set, G_keywords_arr, 1)
	
	_end = arr_len(_set)
	for (_i = 1; _i <= _end; ++_i)
		out_line(sprintf("_B_lex_keywords[\"%s\"] = 1", _set[_i]))
	
	tab_dec()
	out_line("}")
}
# </out_kwds>

# <out_input>
function LEX_NEXT_LINE() {
	return "split(lex_get_line(), _B_lex_input_line, \"\")"
}
function out_lex_io() {
	# Generates the lexer public interface.

	out_line("# read the next character; advance the input")
	out_line("function lex_read_ch() {")
	tab_inc()
	out_line("# Note: the user defines lex_get_line()")
	out_line()
	out_line("_B_lex_curr_ch = (_B_lex_input_line[_B_lex_line_pos++] \"\")")
	out_line("_B_lex_peek_ch = (_B_lex_input_line[_B_lex_line_pos] \"\")")
	out_line("if (_B_lex_peek_ch)")
	tab_inc()
	out_line("return _B_lex_curr_ch")
	tab_dec()
	out_line("else")
	tab_inc()
	out_line(LEX_NEXT_LINE())
	tab_dec()
	out_line("return _B_lex_curr_ch")
	tab_dec()
	out_line("}")

	out_line("# return the last read character")
	out_line("function lex_curr_ch() {return _B_lex_curr_ch}")
	out_line()
	out_line("# return the next character, but do not advance the input")
	out_line("function lex_peek_ch() {return _B_lex_peek_ch}")
	out_line()
	out_line("# return the position in the current line of input")
	out_line("function lex_get_pos() {return (_B_lex_line_pos-1)}")
	out_line()
	out_line("# return the current line number")
	out_line("function lex_get_line_no() {return _B_lex_line_no}")
	out_line()
	out_line("# return the last read token")
	out_line("function lex_curr_tok() {return _B_lex_curr_tok}")
	out_line()
	out_line("# see if your token is the same as the one in the lexer")
	out_line("function lex_match_tok(str) {return (str == _B_lex_curr_tok)}")
	out_line()
	out_line("# clear the lexer write space")
	out_line("function lex_save_init() {_B_lex_saved = \"\"}")
	out_line()
	out_line("# save the last read character")
	out_line("function lex_save_curr_ch() "\
		"{_B_lex_saved = (_B_lex_saved _B_lex_curr_ch)}")
	out_line()
	out_line("# return the saved string")
	out_line("function lex_get_saved() {return _B_lex_saved}")
	out_line()
	out_line("# check if a character is of a particular class")
	out_line("function lex_is_ch_cls(ch, cls) "\
		"{return (cls == _B_lex_ch_tbl[ch])}")
	out_line()
	out_line("# see if the next character in the input is of a particular "\
		"class")
	out_line("function lex_is_next_ch_cls(cls) "\
		"{return (cls == _B_lex_ch_tbl[_B_lex_peek_ch])}")
	out_line()
	out_line("# see if what's in the lexer's write space is a keyword")
	out_line("function lex_is_saved_a_keyword() {"\
		"return (_B_lex_saved in _B_lex_keywords)}")
}
# </out_input>

# <out_lex_next>
# <lex_next>
function out_tree_symb(tree, root,    _next_str, _next_ch, _i, _end) {

	if (ch_ptree_has(tree, root) || ch_ptree_is_word(tree, root)) {

		if (ch_ptree_is_word(tree, root))
			out_line(sprintf("_B_lex_curr_tok = \"%s\"", root))
			
		_next_str = ch_ptree_get(tree, root)
		_end = length(_next_str)
		for (_i = 1; _i <= _end; ++_i) {
			_next_ch = str_ch_at(_next_str, _i)

			if (_end > 1) {
				if (1 == _i) {
					out_line("_B_lex_peeked_ch_cache = lex_peek_ch()")
					out_tabs()
				}			
				print sprintf("%s (\"%s\" == _B_lex_peeked_ch_cache) {",
					(_i == 1) ? "if" : "else if" ,_next_ch)
			} else {
				out_line(sprintf("%s (\"%s\" == lex_peek_ch()) {",
					(_i == 1) ? "if" : "else if" ,_next_ch))
			}
			
			tab_inc()
			out_line("lex_read_ch()")
			out_tree_symb(tree, (root _next_ch))

			tab_dec()
			out_str("} ")
		}

		if (_end >= 1)
			out_line()
	}
}
function out_lex_next(    _i, _end, _cls_set, _cls, _act, _map_cls_chr,
_map_symb, _map_act, _tree, _tmp) {
	# Outputs a big if - else if tree. Branches on character class first and on
	# character value second.
	
	arr_make_set(_cls_set, G_char_tbl_arr, 2)

	out_line("# return the next token; constants are inlined for performance")
	out_line("function lex_next() {")
	tab_inc()
	out_line("while (1) {")
	tab_inc()

	out_line("_B_lex_curr_ch_cls_cache = _B_lex_ch_tbl[lex_read_ch()]")

	map_from_arr(_map_cls_chr, G_char_tbl_arr, 2, 1)
	map_from_arr(_map_symb, G_symbols_arr)
	map_from_arr(_map_act, G_actions_arr)
	ch_ptree_init(_tree)

	for (_tmp in _map_symb) {
		if (!is_constant(_tmp))
			ch_ptree_insert(_tree, _tmp)
	}

	_end = arr_len(_cls_set)
	for (_i = 1; _i <= _end; ++_i) {
		_cls = _cls_set[_i]

		if (1 == _i)
			out_tabs()

		# Note: constants are inlined for performance. E.g.
		# ...
		# function CH_CLS_WORD() {return 1}
		# ...
		# if (CH_CLS_WORD() == curr_ch_cls)
		# ...
		# becomes
		# ...
		# if (1 == curr_ch_cls) # CH_CLS_WORD()
		# ...
		# Same goes for tokens.
		
		print sprintf("%s (%s == _B_lex_curr_ch_cls_cache) { # %s()",
			(1 == _i) ? "if" : "else if",
			ch_cls_to_const_map_get(_cls), _cls)
	
		tab_inc()
		
		if (_cls in _map_act) {
			_act = _map_act[_cls]
			if (match(_act, "\\(\\)$")) {
				# Any action which ends in '()' is assumed to be a callback.
			
				sub("\\(\\)", "()", _act)
				out_line(sprintf("_B_lex_curr_tok = %s", _act))
			} else if (NEXT_CH() == _act) {
				# Back to the top on white space.
				
				out_line("continue")
			} else if (NEXT_LINE() == _act) {
				# Count new lines.
				
				out_line("++_B_lex_line_no")
				out_line("_B_lex_line_pos = 1")
				out_line("continue")
			} else if (is_constant(_act)) {
				# Constants are assumed to be function.
				
				out_line(sprintf("_B_lex_curr_tok = %s()", _act))
			} else {
				# Should never happen.
				
				out_line("!!! ERROR: UNKNOWN ACTION !!!")
			}
		} else {
			# Generate if trees for all tokens which begin with the current
			# character class and are longer than a single character. The
			# class is assumed to represent a single character, i.e. not a
			# range.
			
			_tmp = _map_cls_chr[_cls]
			if (length(_tmp) == 1)
				out_tree_symb(_tree, _tmp)
		}

		tab_dec()
		out_str("} ")
	}
	print "else {"
	tab_inc()
	out_line("_B_lex_curr_tok = on_unknown_ch()")
	tab_dec()
	out_line("}")
	out_line("break")
	tab_dec()
	out_line("}")

	out_line("return _B_lex_curr_tok")
	tab_dec()
	out_line("}")
}
# </lex_next>
# </out_lex_next>

# <out_init>
function out_init() {
	out_line("# call this first")
	out_line("function lex_init() {")
	tab_inc()
	out_line("_lex_init_ch_tbl()")
	out_line("_lex_init_keywords()")
	out_line("_B_lex_line_no = 1")
	out_line("_B_lex_line_pos = 1")
	out_line(sprintf("_B_lex_curr_tok = \"%s\"", TOK_ERR()))
	out_line(LEX_NEXT_LINE())
	tab_dec()
	out_line("}")
}
# </out_init>

# <misc>
function out_public() {
	out_line("# <lex_constants>")
	out_const()
	out_line("# </lex_constants>")
	out_line()
	out_lex_io()
	out_line()
	out_init()
	out_line()
	out_lex_next()
}
function out_private() {
	out_line("# initialize the lexer tables")
	out_kwds()
	out_init_ch_tbl()
}
function generate() {
	out_line("# <lex_awk>")
	out_signature()
	out_line()
	out_line("# <lex_public>")
	out_public()
	out_line("# </lex_public>")
	out_line()
	out_line("# <lex_private>")
	out_private()
	out_line("# </lex_private>")
	out_line("# </lex_awk>")
}
function err_quit(msg) {
	error_quit(msg, SCRIPT_NAME())
}

function ch_cls_to_const_map_add(ch_cls, const) {
	_B_ch_cls_const_map[ch_cls] = const
}
function ch_cls_to_const_map_get(ch_cls) {
	return _B_ch_cls_const_map[ch_cls]
}

function on_help() {
print sprintf("%s -- lex-build awk back end", SCRIPT_NAME())
print ""
print "Classifies characters by table lookup rather than regex. lex_get_line()"
print "has to be implemented by the user to return the next line of input."
print ""
print "Options:"
# Only common
}

function on_version() {
print sprintf("%s %s", SCRIPT_NAME(), SCRIPT_VERSION())
}

function on_begin() {
	arr_init(G_char_tbl_arr)
	arr_init(G_symbols_arr)
	arr_init(G_keywords_arr)
	arr_init(G_patterns_arr)
	arr_init(G_actions_arr)
}
function on_char_tbl() {save_to(G_char_tbl_arr)}
function on_symbols()  {save_to(G_symbols_arr)}
function on_keywords() {save_to(G_keywords_arr)}
function on_patterns() {save_to(G_patterns_arr)}
function on_actions()  {save_to(G_actions_arr)}
function on_end()      {generate()}
# </misc>
